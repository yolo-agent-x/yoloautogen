{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teams\n",
    "\n",
    "Teams define how groups of agents communicate to address tasks. AgentChat provides several preset team configurations to simplify building multi-agent applications.\n",
    "\n",
    "```{include} ../warning.md\n",
    "\n",
    "```\n",
    "\n",
    "A team may consist of a single agent or multiple agents. An important configuration for each team involves defining the order in which agents send messages and determining when the team should terminate.\n",
    "\n",
    "In the following section, we will begin by defining agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from autogen_agentchat import EVENT_LOGGER_NAME\n",
    "from autogen_agentchat.agents import CodingAssistantAgent, ToolUseAssistantAgent\n",
    "from autogen_agentchat.logging import ConsoleLogHandler\n",
    "from autogen_agentchat.task import MaxMessageTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat, SelectorGroupChat\n",
    "from autogen_core.components.models import OpenAIChatCompletionClient\n",
    "from autogen_core.components.tools import FunctionTool\n",
    "\n",
    "# Set up a log handler to print logs to the console.\n",
    "logger = logging.getLogger(EVENT_LOGGER_NAME)\n",
    "logger.addHandler(ConsoleLogHandler())\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Create an OpenAI model client.\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    # api_key=\"sk-...\", # Optional if you have an OPENAI_API_KEY env variable set.\n",
    ")\n",
    "\n",
    "writing_assistant_agent = CodingAssistantAgent(\n",
    "    name=\"writing_assistant_agent\",\n",
    "    system_message=\"You are a helpful assistant that solve tasks by generating text responses and code.\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "\n",
    "async def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is 72 degrees and Sunny.\"\n",
    "\n",
    "\n",
    "get_weather_tool = FunctionTool(get_weather, description=\"Get the weather for a city\")\n",
    "\n",
    "tool_use_agent = ToolUseAssistantAgent(\n",
    "    \"tool_use_agent\",\n",
    "    system_message=\"You are a helpful assistant that solves tasks by only using your tools.\",\n",
    "    model_client=model_client,\n",
    "    registered_tools=[get_weather_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoundRobinGroupChat\n",
    "\n",
    "A team where agents take turns sending messages (in a round robin fashion) until a termination condition is met. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-10-20T09:01:04.692283]:\u001b[0m\n",
      "\n",
      "Write a Haiku about the weather in Paris\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-10-20T09:01:05.961670], tool_use_agent:\u001b[0m\n",
      "\n",
      "Golden sun above,  \n",
      "Paris basks in warmth and light,  \n",
      "Seine flows in sunshine.\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-10-20T09:01:05.962309], Termination:\u001b[0m\n",
      "\n",
      "Maximal number of messages 1 reached, current message count: 1"
     ]
    }
   ],
   "source": [
    "round_robin_team = RoundRobinGroupChat([tool_use_agent, writing_assistant_agent])\n",
    "round_robin_team_result = await round_robin_team.run(\n",
    "    \"Write a Haiku about the weather in Paris\", termination_condition=MaxMessageTermination(max_messages=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can define a team where the agents solve a problem by _writing and executing code_ in a round-robin fashion. \n",
    "\n",
    "```python \n",
    "async with DockerCommandLineCodeExecutor(work_dir=\"coding\") as code_executor:\n",
    "    code_executor_agent = CodeExecutorAgent(\n",
    "        \"code_executor\", code_executor=code_executor)\n",
    "    code_execution_team = RoundRobinGroupChat([writing_assistant_agent, code_executor_agent])\n",
    "    code_execution_team_result = await code_execution_team.run(\"Create a plot of NVDIA and TSLA stock returns YTD from 2024-01-01 and save it to 'nvidia_tesla_2024_ytd.png\", termination_condition=MaxMessageTermination(max_messages=12))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectorGroupChat\n",
    "\n",
    "A team where a generative model (LLM) is used to select the next agent to send a message based on the current conversation history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-10-20T09:01:05.967894]:\u001b[0m\n",
      "\n",
      "What is the weather in paris right now? Also write a haiku about it.\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-10-20T09:01:07.214716], tool_use_agent:\u001b[0m\n",
      "\n",
      "The weather in Paris is currently 72 degrees and Sunny.\n",
      "\n",
      "Here's a Haiku about it:\n",
      "\n",
      "Golden sun above,  \n",
      "Paris basks in warmth and light,  \n",
      "Seine flows in sunshine.\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-10-20T09:01:08.320789], writing_assistant_agent:\u001b[0m\n",
      "\n",
      "I can't check the real-time weather, but you can use a weather website or app to find the current weather in Paris. If you need a fresh haiku, here's one for sunny weather:\n",
      "\n",
      "Paris bathed in sun,  \n",
      "Gentle warmth embraces all,  \n",
      "Seine sparkles with light.\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-10-20T09:01:08.321296], Termination:\u001b[0m\n",
      "\n",
      "Maximal number of messages 2 reached, current message count: 2"
     ]
    }
   ],
   "source": [
    "llm_team = SelectorGroupChat([tool_use_agent, writing_assistant_agent], model_client=model_client)\n",
    "\n",
    "llm_team_result = await llm_team.run(\n",
    "    \"What is the weather in paris right now? Also write a haiku about it.\",\n",
    "    termination_condition=MaxMessageTermination(max_messages=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "In this section, we reviewed how to define model clients, agents, and teams in AgentChat. Here are some other concepts to explore further:\n",
    "\n",
    "- Termination Conditions: Define conditions that determine when a team should stop running. In this sample, we used a `MaxMessageTermination` condition to stop the team after a certain number of messages. Explore other termination conditions supported in the AgentChat package."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
